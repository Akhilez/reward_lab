{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-14T14:03:41.397892Z",
     "start_time": "2023-09-14T14:03:41.392496Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import SupportsFloat, Any, Optional\n",
    "\n",
    "from gymnasium import ActionWrapper, Wrapper\n",
    "from gymnasium.core import WrapperActType, WrapperObsType\n",
    "from gymnasium.spaces import Box\n",
    "from gymnasium.wrappers import TimeLimit, RecordVideo\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from exp.di.mujoco_exp.learning._2_crawler._0_random_target.crawler import WalkToTargetEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class RepeatActionsWrapper(Wrapper):\n",
    "    \"\"\"\n",
    "    One step of wrapped = n steps of unwrapped with same action.\n",
    "    Rewards are averaged.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env, steps_to_repeat: int):\n",
    "        super().__init__(env)\n",
    "        self.steps_to_repeat = steps_to_repeat\n",
    "        assert steps_to_repeat > 1\n",
    "\n",
    "    def step(\n",
    "            self, action: WrapperActType\n",
    "    ) -> tuple[WrapperObsType, SupportsFloat, bool, bool, dict[str, Any]]:\n",
    "        rewards = []\n",
    "        for i in range(self.steps_to_repeat):\n",
    "            obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "            rewards.append(reward)\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "        reward = np.mean(rewards)\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "\n",
    "class SimpleOscillatingPhaseActions(ActionWrapper):\n",
    "    \"\"\"\n",
    "    Accepts actions as phases of oscillators for each motor.\n",
    "    And converts into position values for each motor.\n",
    "    Use this in conjunction with RepeatActionsWrapper.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env, dt, frequencies):\n",
    "        super().__init__(env)\n",
    "        self.dt = dt\n",
    "        self.n = self.env.action_space.shape[0]\n",
    "        self.frequencies = frequencies  # (n,)\n",
    "        self.phases = np.zeros((self.n,))\n",
    "        self._prev_action = self.phases.copy()\n",
    "\n",
    "    def reset(\n",
    "            self, seed: Optional[int] = None, options: Optional[dict[str, Any]] = None\n",
    "    ) -> tuple[WrapperObsType, dict[str, Any]]:\n",
    "        self._prev_action = np.zeros((self.n,))\n",
    "        return super().reset(seed=seed, options=options)\n",
    "\n",
    "    @property\n",
    "    def action_space(self):\n",
    "        return Box(low=-1, high=1, shape=self.phases.shape, dtype=np.float32)\n",
    "\n",
    "    def action(self, phases):\n",
    "        # phases: (n,) in the range (-1,1)\n",
    "\n",
    "        # If a new action is given, change phases.\n",
    "        if np.any(self._prev_action != phases):\n",
    "            phases = np.array(phases)\n",
    "            self._prev_action = phases.copy()\n",
    "\n",
    "            # Scale them to -pi to pi\n",
    "            self.phases = phases * np.pi\n",
    "\n",
    "        value = np.sin(self.phases)\n",
    "\n",
    "        d_phase = self.frequencies  # <-- vanilla oscillators way\n",
    "        self.phases += d_phase * self.dt\n",
    "\n",
    "        # Scale them to 0-1\n",
    "        value = (value + 1) / 2\n",
    "\n",
    "        return value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T14:03:41.590939Z",
     "start_time": "2023-09-14T14:03:41.588259Z"
    }
   },
   "id": "8c14b439103c938b"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def build_env():\n",
    "    time_limit = 500\n",
    "    repeat_steps = 50\n",
    "    dt = 0.1\n",
    "    # record_every_n_episodes = 500\n",
    "    record_every_n_steps = 50000\n",
    "    \n",
    "    env = WalkToTargetEnv(n_legs=4)\n",
    "    env = TimeLimit(env, time_limit)\n",
    "    env = RecordVideo(\n",
    "        env, \n",
    "        video_folder='/Users/akhildevarashetti/code/reward_lab/exp/di/mujoco_exp/learning/_2_crawler/_0_random_target/agents/vids',\n",
    "        # episode_trigger=lambda episode: episode % record_every_n_episodes == 0,\n",
    "        step_trigger=lambda step: step % record_every_n_steps == 0,\n",
    "        video_length=time_limit,\n",
    "        name_prefix='kuramoto_learner',\n",
    "    )\n",
    "    env = SimpleOscillatingPhaseActions(env, dt=dt, frequencies=np.ones(env.action_space.shape) * 5)\n",
    "    env = RepeatActionsWrapper(env, steps_to_repeat=repeat_steps)\n",
    "    return env"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T14:03:41.786213Z",
     "start_time": "2023-09-14T14:03:41.781460Z"
    }
   },
   "id": "a6b21f1e0c95f39f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env = build_env()\n",
    "rewards = []\n",
    "\n",
    "env.reset()\n",
    "while True:\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, terminated, truncated, _ = env.step(action)\n",
    "    rewards.append(reward)\n",
    "    if truncated or terminated:\n",
    "        break\n",
    "env.close()\n",
    "\n",
    "plt.plot(rewards)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c66a8a74ef9804f6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
